{"timestamp":"2025-12-18T10:57:23.539249Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-18T10:57:23.540493Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/lakehouse.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-18T10:57:23.575656Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2025-12-18T10:57:23.576753Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '\\n        docker exec spark-iceberg         spark-submit /home/iceberg/jobs/load_and_insert.py\\n        ']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":88}
{"timestamp":"2025-12-18T10:57:23.588616Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-18T10:57:26.767736Z","level":"info","event":"25/12/18 10:57:26 INFO SparkContext: Running Spark version 3.5.5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.770727Z","level":"info","event":"25/12/18 10:57:26 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.772076Z","level":"info","event":"25/12/18 10:57:26 INFO SparkContext: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.855026Z","level":"info","event":"25/12/18 10:57:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.993044Z","level":"info","event":"25/12/18 10:57:26 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.993829Z","level":"info","event":"25/12/18 10:57:26 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.994054Z","level":"info","event":"25/12/18 10:57:26 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:26.995071Z","level":"info","event":"25/12/18 10:57:26 INFO SparkContext: Submitted application: load_and_insert.py","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.021820Z","level":"info","event":"25/12/18 10:57:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.035248Z","level":"info","event":"25/12/18 10:57:27 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.036515Z","level":"info","event":"25/12/18 10:57:27 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.099509Z","level":"info","event":"25/12/18 10:57:27 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.100183Z","level":"info","event":"25/12/18 10:57:27 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.101836Z","level":"info","event":"25/12/18 10:57:27 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.103423Z","level":"info","event":"25/12/18 10:57:27 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.103663Z","level":"info","event":"25/12/18 10:57:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.489174Z","level":"info","event":"25/12/18 10:57:27 INFO Utils: Successfully started service 'sparkDriver' on port 35245.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.526654Z","level":"info","event":"25/12/18 10:57:27 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.570580Z","level":"info","event":"25/12/18 10:57:27 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.598875Z","level":"info","event":"25/12/18 10:57:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.599698Z","level":"info","event":"25/12/18 10:57:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.610808Z","level":"info","event":"25/12/18 10:57:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.638080Z","level":"info","event":"25/12/18 10:57:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b00edb65-7aee-4060-84fd-e1bd326dc65d","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.661056Z","level":"info","event":"25/12/18 10:57:27 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.688300Z","level":"info","event":"25/12/18 10:57:27 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.870292Z","level":"info","event":"25/12/18 10:57:27 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.949847Z","level":"info","event":"25/12/18 10:57:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:27.960775Z","level":"info","event":"25/12/18 10:57:27 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.136035Z","level":"info","event":"25/12/18 10:57:28 INFO Executor: Starting executor ID driver on host 39a6647a13a1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.136276Z","level":"info","event":"25/12/18 10:57:28 INFO Executor: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.138245Z","level":"info","event":"25/12/18 10:57:28 INFO Executor: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.151140Z","level":"info","event":"25/12/18 10:57:28 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.153894Z","level":"info","event":"25/12/18 10:57:28 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4abf83e3 for default.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.198429Z","level":"info","event":"25/12/18 10:57:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41641.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.198677Z","level":"info","event":"25/12/18 10:57:28 INFO NettyBlockTransferService: Server created on 39a6647a13a1:41641","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.198818Z","level":"info","event":"25/12/18 10:57:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.214249Z","level":"info","event":"25/12/18 10:57:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 39a6647a13a1, 41641, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.228169Z","level":"info","event":"25/12/18 10:57:28 INFO BlockManagerMasterEndpoint: Registering block manager 39a6647a13a1:41641 with 434.4 MiB RAM, BlockManagerId(driver, 39a6647a13a1, 41641, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.231799Z","level":"info","event":"25/12/18 10:57:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 39a6647a13a1, 41641, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.237127Z","level":"info","event":"25/12/18 10:57:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 39a6647a13a1, 41641, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:28.811947Z","level":"info","event":"25/12/18 10:57:28 INFO SingleEventLogFileWriter: Logging events to file:/home/iceberg/spark-events/local-1766055448061.inprogress","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.307746Z","level":"info","event":"25/12/18 10:57:29 WARN SparkSession: Cannot use org.projectnessie.spark.extensions.NessieSparkSessionExtensions to configure session extensions.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308051Z","level":"info","event":"java.lang.ClassNotFoundException: org.projectnessie.spark.extensions.NessieSparkSessionExtensions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308215Z","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308324Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308435Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308551Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308684Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308810Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.308931Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309080Z","level":"info","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309202Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1367)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309324Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309468Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309595Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309711Z","level":"info","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309813Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$applyExtensions(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.309918Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:105)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310056Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310150Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310253Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310396Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310550Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310646Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310729Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310822Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.310913Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.311039Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.311141Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.311233Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.311322Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.331670Z","level":"info","event":"25/12/18 10:57:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:29.335198Z","level":"info","event":"25/12/18 10:57:29 INFO SharedState: Warehouse path is 'file:/opt/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:30.505690Z","level":"info","event":"25/12/18 10:57:30 INFO InMemoryFileIndex: It took 75 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:30.713052Z","level":"info","event":"25/12/18 10:57:30 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:33.907135Z","level":"info","event":"25/12/18 10:57:33 INFO CatalogUtil: Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:34.250638Z","level":"info","event":"25/12/18 10:57:34 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:34.254642Z","level":"info","event":"25/12/18 10:57:34 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.110154Z","level":"info","event":"25/12/18 10:57:35 INFO CodeGenerator: Code generated in 432.748219 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.186069Z","level":"info","event":"25/12/18 10:57:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.267497Z","level":"info","event":"25/12/18 10:57:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.272265Z","level":"info","event":"25/12/18 10:57:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 39a6647a13a1:41641 (size: 35.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.280331Z","level":"info","event":"25/12/18 10:57:35 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.297917Z","level":"info","event":"25/12/18 10:57:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4729440 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.473892Z","level":"info","event":"25/12/18 10:57:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.508316Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.513341Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.513572Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.513676Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.520466Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.643624Z","level":"info","event":"25/12/18 10:57:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.646046Z","level":"info","event":"25/12/18 10:57:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.647098Z","level":"info","event":"25/12/18 10:57:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 39a6647a13a1:41641 (size: 6.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.648490Z","level":"info","event":"25/12/18 10:57:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.673554Z","level":"info","event":"25/12/18 10:57:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.675079Z","level":"info","event":"25/12/18 10:57:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.727074Z","level":"info","event":"25/12/18 10:57:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (39a6647a13a1, executor driver, partition 0, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.743663Z","level":"info","event":"25/12/18 10:57:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.864530Z","level":"info","event":"25/12/18 10:57:35 INFO CodeGenerator: Code generated in 14.584184 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.868805Z","level":"info","event":"25/12/18 10:57:35 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 0-4729440, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.891021Z","level":"info","event":"25/12/18 10:57:35 INFO CodeGenerator: Code generated in 14.034966 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:35.993901Z","level":"info","event":"25/12/18 10:57:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1753 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.014430Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 301 ms on 39a6647a13a1 (executor driver) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.025576Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.038065Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.489 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.042281Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.042517Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.050065Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.583587 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.082051Z","level":"info","event":"25/12/18 10:57:36 INFO CodeGenerator: Code generated in 14.498038 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.171808Z","level":"info","event":"25/12/18 10:57:36 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.172074Z","level":"info","event":"25/12/18 10:57:36 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.185631Z","level":"info","event":"25/12/18 10:57:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.200854Z","level":"info","event":"25/12/18 10:57:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.203419Z","level":"info","event":"25/12/18 10:57:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 39a6647a13a1:41641 (size: 35.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.205778Z","level":"info","event":"25/12/18 10:57:36 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.207102Z","level":"info","event":"25/12/18 10:57:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4729440 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.299553Z","level":"info","event":"25/12/18 10:57:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.301551Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.301782Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.301888Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.306173Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.306428Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.344893Z","level":"info","event":"25/12/18 10:57:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 28.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.347769Z","level":"info","event":"25/12/18 10:57:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.349265Z","level":"info","event":"25/12/18 10:57:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 39a6647a13a1:41641 (size: 13.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.349918Z","level":"info","event":"25/12/18 10:57:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.351481Z","level":"info","event":"25/12/18 10:57:36 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.351756Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.356914Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (39a6647a13a1, executor driver, partition 0, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.358639Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (39a6647a13a1, executor driver, partition 1, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.358856Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (39a6647a13a1, executor driver, partition 2, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.359003Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (39a6647a13a1, executor driver, partition 3, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.360034Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (39a6647a13a1, executor driver, partition 4, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.360502Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (39a6647a13a1, executor driver, partition 5, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.366500Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (39a6647a13a1, executor driver, partition 6, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.366755Z","level":"info","event":"25/12/18 10:57:36 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (39a6647a13a1, executor driver, partition 7, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.366910Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.376506Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.376761Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.379126Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.395423Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.395635Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.410040Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.424049Z","level":"info","event":"25/12/18 10:57:36 INFO Executor: Running task 7.0 in stage 1.0 (TID 8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.455252Z","level":"info","event":"25/12/18 10:57:36 INFO CodeGenerator: Code generated in 20.700934 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.462814Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 23647200-28376640, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.463081Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 4729440-9458880, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.463213Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 33106080-33641222, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.463325Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 28376640-33106080, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.463414Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 18917760-23647200, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.467154Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 9458880-14188320, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.472863Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 0-4729440, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.475304Z","level":"info","event":"25/12/18 10:57:36 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 14188320-18917760, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:36.575100Z","level":"info","event":"25/12/18 10:57:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 39a6647a13a1:41641 in memory (size: 6.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:37.139085Z","level":"info","event":"25/12/18 10:57:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 39a6647a13a1:41641 in memory (size: 35.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:37.352843Z","level":"info","event":"25/12/18 10:57:37 INFO Executor: Finished task 7.0 in stage 1.0 (TID 8). 1689 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:37.359144Z","level":"info","event":"25/12/18 10:57:37 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 995 ms on 39a6647a13a1 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.088135Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.107543Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1745 ms on 39a6647a13a1 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.220265Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.226341Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1864 ms on 39a6647a13a1 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.260334Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.279360Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1906 ms on 39a6647a13a1 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.328231Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.328470Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1964 ms on 39a6647a13a1 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.378234Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.386886Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 2027 ms on 39a6647a13a1 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.409463Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.413249Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2059 ms on 39a6647a13a1 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.434269Z","level":"info","event":"25/12/18 10:57:38 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1595 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.439768Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2080 ms on 39a6647a13a1 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.440051Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.442542Z","level":"info","event":"25/12/18 10:57:38 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 2.131 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.447973Z","level":"info","event":"25/12/18 10:57:38 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.448250Z","level":"info","event":"25/12/18 10:57:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:38.457035Z","level":"info","event":"25/12/18 10:57:38 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 2.153448 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.086556Z","level":"info","event":"25/12/18 10:57:39 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {gc.enabled=false, write.metadata.delete-after-commit.enabled=false}","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.131596Z","level":"info","event":"25/12/18 10:57:39 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.226681Z","level":"info","event":"25/12/18 10:57:39 INFO SparkWrite: Requesting 0 bytes advisory partition size for table youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.226837Z","level":"info","event":"25/12/18 10:57:39 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.229154Z","level":"info","event":"25/12/18 10:57:39 INFO SparkWrite: Requesting [] as write ordering for table youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.242382Z","level":"info","event":"25/12/18 10:57:39 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.242646Z","level":"info","event":"25/12/18 10:57:39 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.256418Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 208.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.272006Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.275817Z","level":"info","event":"25/12/18 10:57:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 39a6647a13a1:41641 (size: 35.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.276071Z","level":"info","event":"25/12/18 10:57:39 INFO SparkContext: Created broadcast 4 from create at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.283119Z","level":"info","event":"25/12/18 10:57:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4729440 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.305428Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.362781Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.365249Z","level":"info","event":"25/12/18 10:57:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 39a6647a13a1:41641 (size: 3.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.365606Z","level":"info","event":"25/12/18 10:57:39 INFO SparkContext: Created broadcast 5 from broadcast at SparkWrite.java:193","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.368265Z","level":"info","event":"25/12/18 10:57:39 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=youtubes.video2025, format=PARQUET). The input RDD has 8 partitions.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.384055Z","level":"info","event":"25/12/18 10:57:39 INFO SparkContext: Starting job: create at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.386492Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Got job 2 (create at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.386742Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Final stage: ResultStage 2 (create at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.386868Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.387978Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.391486Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at create at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.394624Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.5 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.397191Z","level":"info","event":"25/12/18 10:57:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.398868Z","level":"info","event":"25/12/18 10:57:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 39a6647a13a1:41641 (size: 7.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.402625Z","level":"info","event":"25/12/18 10:57:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.402866Z","level":"info","event":"25/12/18 10:57:39 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at create at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.402985Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.405183Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (39a6647a13a1, executor driver, partition 0, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.405413Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (39a6647a13a1, executor driver, partition 1, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.406810Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (39a6647a13a1, executor driver, partition 2, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.407904Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (39a6647a13a1, executor driver, partition 3, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.412425Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (39a6647a13a1, executor driver, partition 4, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.413823Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (39a6647a13a1, executor driver, partition 5, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.414049Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (39a6647a13a1, executor driver, partition 6, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.414201Z","level":"info","event":"25/12/18 10:57:39 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (39a6647a13a1, executor driver, partition 7, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.414303Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 10)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.416629Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 2.0 in stage 2.0 (TID 11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.416835Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 4.0 in stage 2.0 (TID 13)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.416956Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 6.0 in stage 2.0 (TID 15)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.417072Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.421613Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 7.0 in stage 2.0 (TID 16)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.421760Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 5.0 in stage 2.0 (TID 14)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:39.429464Z","level":"info","event":"25/12/18 10:57:39 INFO Executor: Running task 3.0 in stage 2.0 (TID 12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.362269Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.362579Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.362716Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.363005Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.363155Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.364581Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.364748Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.364917Z","level":"info","event":"25/12/18 10:57:40 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.663552Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 23647200-28376640, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.663767Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 0-4729440, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.663882Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 4729440-9458880, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.663971Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 9458880-14188320, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.664067Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 33106080-33641222, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.669199Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 28376640-33106080, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.671417Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 14188320-18917760, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.671599Z","level":"info","event":"25/12/18 10:57:40 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 18917760-23647200, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:40.746403Z","level":"info","event":"25/12/18 10:57:40 INFO CodeGenerator: Code generated in 34.308957 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:41.169240Z","level":"info","event":"25/12/18 10:57:41 INFO DataWritingSparkTask: Writer for partition 7 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:42.697343Z","level":"info","event":"25/12/18 10:57:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 39a6647a13a1:41641 in memory (size: 13.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:42.725227Z","level":"info","event":"25/12/18 10:57:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 39a6647a13a1:41641 in memory (size: 35.4 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.358059Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 0 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.365557Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 6 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.582695Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 5 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.633849Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 3 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.829558Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 2 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:43.863433Z","level":"info","event":"25/12/18 10:57:43 INFO DataWritingSparkTask: Writer for partition 1 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.014801Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Writer for partition 4 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.735327Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 1 (task 10, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.735646Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 7 (task 16, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.735814Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 6 (task 15, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.735962Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 0 (task 9, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.737587Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 5 (task 14, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.737818Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 2 (task 11, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.737926Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 3 (task 12, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.738022Z","level":"info","event":"25/12/18 10:57:44 INFO DataWritingSparkTask: Committed partition 4 (task 13, attempt 0, stage 2.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.753800Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 4.0 in stage 2.0 (TID 13). 5058 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.762022Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 7.0 in stage 2.0 (TID 16). 4963 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.768287Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 5022 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.768748Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 2.0 in stage 2.0 (TID 11). 5018 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.768982Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 5.0 in stage 2.0 (TID 14). 5011 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.792472Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 3.0 in stage 2.0 (TID 12). 5003 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.792690Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 10). 5033 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.801207Z","level":"info","event":"25/12/18 10:57:44 INFO Executor: Finished task 6.0 in stage 2.0 (TID 15). 5036 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.809284Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 5390 ms on 39a6647a13a1 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.809539Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 5396 ms on 39a6647a13a1 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.809668Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 5392 ms on 39a6647a13a1 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.810780Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 5394 ms on 39a6647a13a1 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.811039Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 5403 ms on 39a6647a13a1 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.811654Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 5402 ms on 39a6647a13a1 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.816615Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 5411 ms on 39a6647a13a1 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.818509Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 5406 ms on 39a6647a13a1 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.818732Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.823759Z","level":"info","event":"25/12/18 10:57:44 INFO DAGScheduler: ResultStage 2 (create at NativeMethodAccessorImpl.java:0) finished in 5.433 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.828465Z","level":"info","event":"25/12/18 10:57:44 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.829011Z","level":"info","event":"25/12/18 10:57:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.831541Z","level":"info","event":"25/12/18 10:57:44 INFO DAGScheduler: Job 2 finished: create at NativeMethodAccessorImpl.java:0, took 5.440123 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.835196Z","level":"info","event":"25/12/18 10:57:44 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=youtubes.video2025, format=PARQUET) is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:44.900765Z","level":"info","event":"25/12/18 10:57:44 INFO SparkWrite: Committing append with 8 new data files to table youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.277823Z","level":"info","event":"25/12/18 10:57:45 INFO SnapshotProducer: Committed snapshot 1618996696238541402 (MergeAppend)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.471378Z","level":"info","event":"25/12/18 10:57:45 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=youtubes.video2025, snapshotId=1618996696238541402, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.510270298S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=8}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=8}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=155686}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=155686}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=13410614}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=13410614}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.5, app-id=local-1766055448061, engine-name=spark, iceberg-version=Apache Iceberg 1.8.1 (commit 9ce0fcf0af7becf25ad9fc996c3bad2afdcfd33d)}}","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.471644Z","level":"info","event":"25/12/18 10:57:45 INFO SparkWrite: Committed in 571 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.478285Z","level":"info","event":"25/12/18 10:57:45 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=youtubes.video2025, format=PARQUET) committed.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.673076Z","level":"info","event":"25/12/18 10:57:45 INFO NessieIcebergClient: Committed 'youtubes.video2025' against 'Branch{name=main, metadata=null, hash=5cdbd939fe069f3d0f1d5d6ed2d01ecfa5da627719624f9a81b41c9c9c954e71}', expected commit-id was 'f3b0467e53c01fd0d3330d96ee1a8a6d2612dc2480e51742b05c1fbd0868fa76'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.673340Z","level":"info","event":"25/12/18 10:57:45 INFO BaseMetastoreTableOperations: Successfully committed to table youtubes.video2025 in 192 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.755940Z","level":"info","event":"25/12/18 10:57:45 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: s3://warehouse/wh/youtubes/video2025_91711754-ad8e-4ea6-a5d6-4b1008566c23/metadata/00000-ff068613-6a24-4b10-b990-a148c138777f.metadata.json","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.767295Z","level":"info","event":"25/12/18 10:57:45 INFO NessieUtil: loadTableMetadata for 'youtubes.video2025' from location 's3://warehouse/wh/youtubes/video2025_91711754-ad8e-4ea6-a5d6-4b1008566c23/metadata/00000-ff068613-6a24-4b10-b990-a148c138777f.metadata.json' at 'Branch{name=main, metadata=null, hash=5cdbd939fe069f3d0f1d5d6ed2d01ecfa5da627719624f9a81b41c9c9c954e71}'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.771158Z","level":"info","event":"25/12/18 10:57:45 INFO BaseMetastoreCatalog: Table loaded by catalog: nessie.youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.794989Z","level":"info","event":"25/12/18 10:57:45 INFO SparkWrite: Requesting 0 bytes advisory partition size for table nessie.youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.795220Z","level":"info","event":"25/12/18 10:57:45 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table nessie.youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.795346Z","level":"info","event":"25/12/18 10:57:45 INFO SparkWrite: Requesting [] as write ordering for table nessie.youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.804693Z","level":"info","event":"25/12/18 10:57:45 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.804947Z","level":"info","event":"25/12/18 10:57:45 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.814684Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 208.9 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.828502Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.831013Z","level":"info","event":"25/12/18 10:57:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 39a6647a13a1:41641 (size: 35.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.835000Z","level":"info","event":"25/12/18 10:57:45 INFO SparkContext: Created broadcast 7 from append at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.835242Z","level":"info","event":"25/12/18 10:57:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4729440 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.846281Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.0 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.851958Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.856320Z","level":"info","event":"25/12/18 10:57:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 39a6647a13a1:41641 (size: 3.6 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.857790Z","level":"info","event":"25/12/18 10:57:45 INFO SparkContext: Created broadcast 8 from broadcast at SparkWrite.java:193","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.859997Z","level":"info","event":"25/12/18 10:57:45 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=nessie.youtubes.video2025, format=PARQUET). The input RDD has 8 partitions.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.863216Z","level":"info","event":"25/12/18 10:57:45 INFO SparkContext: Starting job: append at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.865299Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Got job 3 (append at NativeMethodAccessorImpl.java:0) with 8 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.865523Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Final stage: ResultStage 3 (append at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.865638Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.871694Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.873200Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at append at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.876814Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 14.5 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.893823Z","level":"info","event":"25/12/18 10:57:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.898769Z","level":"info","event":"25/12/18 10:57:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 39a6647a13a1:41641 (size: 7.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.910860Z","level":"info","event":"25/12/18 10:57:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911068Z","level":"info","event":"25/12/18 10:57:45 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at append at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911221Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911313Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 17) (39a6647a13a1, executor driver, partition 0, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911423Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 18) (39a6647a13a1, executor driver, partition 1, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911508Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 19) (39a6647a13a1, executor driver, partition 2, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.911591Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 20) (39a6647a13a1, executor driver, partition 3, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.920340Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 21) (39a6647a13a1, executor driver, partition 4, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.920625Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 22) (39a6647a13a1, executor driver, partition 5, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.920769Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 23) (39a6647a13a1, executor driver, partition 6, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.920887Z","level":"info","event":"25/12/18 10:57:45 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 24) (39a6647a13a1, executor driver, partition 7, PROCESS_LOCAL, 9597 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.932434Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 1.0 in stage 3.0 (TID 18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.932655Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 0.0 in stage 3.0 (TID 17)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.932785Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 4.0 in stage 3.0 (TID 21)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.939605Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 2.0 in stage 3.0 (TID 19)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.940262Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 5.0 in stage 3.0 (TID 22)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.940384Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 7.0 in stage 3.0 (TID 24)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.940488Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 3.0 in stage 3.0 (TID 20)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.940588Z","level":"info","event":"25/12/18 10:57:45 INFO Executor: Running task 6.0 in stage 3.0 (TID 23)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.969426Z","level":"info","event":"25/12/18 10:57:45 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.969725Z","level":"info","event":"25/12/18 10:57:45 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.969975Z","level":"info","event":"25/12/18 10:57:45 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.970140Z","level":"info","event":"25/12/18 10:57:45 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 23647200-28376640, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.982367Z","level":"info","event":"25/12/18 10:57:45 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 33106080-33641222, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.982592Z","level":"info","event":"25/12/18 10:57:45 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.982709Z","level":"info","event":"25/12/18 10:57:45 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 4729440-9458880, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.982813Z","level":"info","event":"25/12/18 10:57:45 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 18917760-23647200, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.982914Z","level":"info","event":"25/12/18 10:57:45 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:45.993345Z","level":"info","event":"25/12/18 10:57:45 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 9458880-14188320, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.040440Z","level":"info","event":"25/12/18 10:57:46 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.040697Z","level":"info","event":"25/12/18 10:57:46 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.043920Z","level":"info","event":"25/12/18 10:57:46 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 28376640-33106080, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.048812Z","level":"info","event":"25/12/18 10:57:46 INFO CodecPool: Got brand-new compressor [.zstd]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.076700Z","level":"info","event":"25/12/18 10:57:46 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 0-4729440, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.099856Z","level":"info","event":"25/12/18 10:57:46 INFO FileScanRDD: Reading File path: file:///home/data/youtube_video.csv, range: 14188320-18917760, partition values: [empty row]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.341270Z","level":"info","event":"25/12/18 10:57:46 INFO DataWritingSparkTask: Writer for partition 7 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.349121Z","level":"info","event":"25/12/18 10:57:46 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 39a6647a13a1:41641 in memory (size: 3.3 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.397106Z","level":"info","event":"25/12/18 10:57:46 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 39a6647a13a1:41641 in memory (size: 7.4 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.429881Z","level":"info","event":"25/12/18 10:57:46 INFO DataWritingSparkTask: Committed partition 7 (task 24, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.430275Z","level":"info","event":"25/12/18 10:57:46 INFO Executor: Finished task 7.0 in stage 3.0 (TID 24). 4920 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:46.441528Z","level":"info","event":"25/12/18 10:57:46 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 24) in 524 ms on 39a6647a13a1 (executor driver) (1/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.203707Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 0 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.204522Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 5 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.308478Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 2 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.321998Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 3 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.367264Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 6 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.417152Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 0 (task 17, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.428519Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 17). 5023 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.447022Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 17) in 1541 ms on 39a6647a13a1 (executor driver) (2/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.530923Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 1 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.600986Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 5 (task 22, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.601341Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 5.0 in stage 3.0 (TID 22). 4968 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.601697Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 22) in 1687 ms on 39a6647a13a1 (executor driver) (3/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.647542Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 2 (task 19, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.662644Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 3 (task 20, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.663161Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 3.0 in stage 3.0 (TID 20). 4960 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.663427Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Writer for partition 4 is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.663590Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 20) in 1753 ms on 39a6647a13a1 (executor driver) (4/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.663711Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 2.0 in stage 3.0 (TID 19). 4975 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.669725Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 19) in 1760 ms on 39a6647a13a1 (executor driver) (5/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.688922Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 1 (task 18, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.694278Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 1.0 in stage 3.0 (TID 18). 4990 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.697979Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 18) in 1790 ms on 39a6647a13a1 (executor driver) (6/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.698355Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 6 (task 23, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.704441Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 6.0 in stage 3.0 (TID 23). 4993 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.711217Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 23) in 1790 ms on 39a6647a13a1 (executor driver) (7/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.792890Z","level":"info","event":"25/12/18 10:57:47 INFO DataWritingSparkTask: Committed partition 4 (task 21, attempt 0, stage 3.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.794079Z","level":"info","event":"25/12/18 10:57:47 INFO Executor: Finished task 4.0 in stage 3.0 (TID 21). 5015 bytes result sent to driver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.796382Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 21) in 1883 ms on 39a6647a13a1 (executor driver) (8/8)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.797241Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.801489Z","level":"info","event":"25/12/18 10:57:47 INFO DAGScheduler: ResultStage 3 (append at NativeMethodAccessorImpl.java:0) finished in 1.927 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.801725Z","level":"info","event":"25/12/18 10:57:47 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.801872Z","level":"info","event":"25/12/18 10:57:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.810773Z","level":"info","event":"25/12/18 10:57:47 INFO DAGScheduler: Job 3 finished: append at NativeMethodAccessorImpl.java:0, took 1.941689 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.811016Z","level":"info","event":"25/12/18 10:57:47 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=nessie.youtubes.video2025, format=PARQUET) is committing.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:47.812716Z","level":"info","event":"25/12/18 10:57:47 INFO SparkWrite: Committing append with 8 new data files to table nessie.youtubes.video2025","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.002153Z","level":"info","event":"25/12/18 10:57:47 INFO NessieIcebergClient: Committed 'youtubes.video2025' against 'Branch{name=main, metadata=null, hash=87d9b35c3177d0317feb915fced0151e2205400ec37b2dea4b14c6641d8fecee}', expected commit-id was '5cdbd939fe069f3d0f1d5d6ed2d01ecfa5da627719624f9a81b41c9c9c954e71'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.002449Z","level":"info","event":"25/12/18 10:57:47 INFO BaseMetastoreTableOperations: Successfully committed to table youtubes.video2025 in 44 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.002570Z","level":"info","event":"25/12/18 10:57:47 INFO SnapshotProducer: Committed snapshot 5208475116112099418 (MergeAppend)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.057227Z","level":"info","event":"25/12/18 10:57:48 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: s3://warehouse/wh/youtubes/video2025_91711754-ad8e-4ea6-a5d6-4b1008566c23/metadata/00001-c5176021-32ad-4f15-ba3e-586cf0ed877d.metadata.json","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.071959Z","level":"info","event":"25/12/18 10:57:48 INFO NessieUtil: loadTableMetadata for 'youtubes.video2025' from location 's3://warehouse/wh/youtubes/video2025_91711754-ad8e-4ea6-a5d6-4b1008566c23/metadata/00001-c5176021-32ad-4f15-ba3e-586cf0ed877d.metadata.json' at 'Branch{name=main, metadata=null, hash=87d9b35c3177d0317feb915fced0151e2205400ec37b2dea4b14c6641d8fecee}'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.072229Z","level":"info","event":"25/12/18 10:57:48 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=nessie.youtubes.video2025, snapshotId=5208475116112099418, sequenceNumber=2, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.212084946S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=8}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=16}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=155686}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=311372}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=13410614}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=26821228}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.5, app-id=local-1766055448061, engine-name=spark, iceberg-version=Apache Iceberg 1.8.1 (commit 9ce0fcf0af7becf25ad9fc996c3bad2afdcfd33d)}}","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.072395Z","level":"info","event":"25/12/18 10:57:48 INFO SparkWrite: Committed in 259 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.072520Z","level":"info","event":"25/12/18 10:57:48 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=nessie.youtubes.video2025, format=PARQUET) committed.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.073952Z","level":"info","event":"25/12/18 10:57:48 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.091281Z","level":"info","event":"25/12/18 10:57:48 INFO SparkUI: Stopped Spark web UI at http://39a6647a13a1:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.110900Z","level":"info","event":"25/12/18 10:57:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.131760Z","level":"info","event":"25/12/18 10:57:48 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.132231Z","level":"info","event":"25/12/18 10:57:48 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.137126Z","level":"info","event":"25/12/18 10:57:48 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.141816Z","level":"info","event":"25/12/18 10:57:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.154535Z","level":"info","event":"25/12/18 10:57:48 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.244446Z","level":"info","event":"25/12/18 10:57:48 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.244707Z","level":"info","event":"25/12/18 10:57:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-3086b550-4a8b-434f-b285-845d4ab60303","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.252456Z","level":"info","event":"25/12/18 10:57:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb13d31b-3141-47de-88cc-3ea3b5965249","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.261537Z","level":"info","event":"25/12/18 10:57:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-3086b550-4a8b-434f-b285-845d4ab60303/pyspark-317877b2-0353-4add-8f2c-c8bea6f5109d","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:48.702574Z","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":110}
{"timestamp":"2025-12-18T10:57:48.703633Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b311b-1216-7a61-b4fd-0b4e733bd119'), task_id='load_and_insert', dag_id='youtube_iceberg_pipeline', run_id='manual__2025-12-18T10:56:56.314021+00:00', try_number=1, dag_version_id=UUID('019b310c-6ed5-77d7-b13f-281f142c1798'), map_index=-1, hostname='d7cb02c224fd', context_carrier={}, task=<Task(BashOperator): load_and_insert>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 12, 18, 10, 57, 23, 302181, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1352}
