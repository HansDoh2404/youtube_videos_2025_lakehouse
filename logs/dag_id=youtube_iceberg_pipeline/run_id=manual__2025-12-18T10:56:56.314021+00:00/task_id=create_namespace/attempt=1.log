{"timestamp":"2025-12-18T10:57:00.762837Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-18T10:57:00.764078Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/lakehouse.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-18T10:57:00.860930Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2025-12-18T10:57:00.862500Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '\\n        docker exec spark-iceberg         spark-submit /home/iceberg/jobs/create_namespace.py\\n        ']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":88}
{"timestamp":"2025-12-18T10:57:00.880366Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-18T10:57:04.370760Z","level":"info","event":"25/12/18 10:57:04 INFO SparkContext: Running Spark version 3.5.5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.373804Z","level":"info","event":"25/12/18 10:57:04 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.374330Z","level":"info","event":"25/12/18 10:57:04 INFO SparkContext: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.463830Z","level":"info","event":"25/12/18 10:57:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.614526Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.615067Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.615283Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.616549Z","level":"info","event":"25/12/18 10:57:04 INFO SparkContext: Submitted application: create_namespace.py","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.647400Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.662284Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.662541Z","level":"info","event":"25/12/18 10:57:04 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.736364Z","level":"info","event":"25/12/18 10:57:04 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.737190Z","level":"info","event":"25/12/18 10:57:04 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.737938Z","level":"info","event":"25/12/18 10:57:04 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.741808Z","level":"info","event":"25/12/18 10:57:04 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:04.744445Z","level":"info","event":"25/12/18 10:57:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.147763Z","level":"info","event":"25/12/18 10:57:05 INFO Utils: Successfully started service 'sparkDriver' on port 34443.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.196141Z","level":"info","event":"25/12/18 10:57:05 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.249634Z","level":"info","event":"25/12/18 10:57:05 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.276913Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.278673Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.286212Z","level":"info","event":"25/12/18 10:57:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.313522Z","level":"info","event":"25/12/18 10:57:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46356435-e1c0-4b23-8872-1471e36a88a7","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.338613Z","level":"info","event":"25/12/18 10:57:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.368230Z","level":"info","event":"25/12/18 10:57:05 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.554864Z","level":"info","event":"25/12/18 10:57:05 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.653688Z","level":"info","event":"25/12/18 10:57:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.670271Z","level":"info","event":"25/12/18 10:57:05 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.862642Z","level":"info","event":"25/12/18 10:57:05 INFO Executor: Starting executor ID driver on host 39a6647a13a1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.863260Z","level":"info","event":"25/12/18 10:57:05 INFO Executor: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.864249Z","level":"info","event":"25/12/18 10:57:05 INFO Executor: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.886010Z","level":"info","event":"25/12/18 10:57:05 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.886259Z","level":"info","event":"25/12/18 10:57:05 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@594de03b for default.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.936402Z","level":"info","event":"25/12/18 10:57:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34639.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.936922Z","level":"info","event":"25/12/18 10:57:05 INFO NettyBlockTransferService: Server created on 39a6647a13a1:34639","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.939408Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.948976Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 39a6647a13a1, 34639, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.953650Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManagerMasterEndpoint: Registering block manager 39a6647a13a1:34639 with 434.4 MiB RAM, BlockManagerId(driver, 39a6647a13a1, 34639, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.957310Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 39a6647a13a1, 34639, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:05.960029Z","level":"info","event":"25/12/18 10:57:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 39a6647a13a1, 34639, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.325315Z","level":"info","event":"25/12/18 10:57:06 INFO SingleEventLogFileWriter: Logging events to file:/home/iceberg/spark-events/local-1766055425790.inprogress","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.821279Z","level":"info","event":"25/12/18 10:57:06 WARN SparkSession: Cannot use org.projectnessie.spark.extensions.NessieSparkSessionExtensions to configure session extensions.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.821557Z","level":"info","event":"java.lang.ClassNotFoundException: org.projectnessie.spark.extensions.NessieSparkSessionExtensions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.821700Z","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.821830Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.821968Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822107Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822233Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822352Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822507Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822629Z","level":"info","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822759Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1367)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.822897Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823019Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823162Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823291Z","level":"info","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823411Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$applyExtensions(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823572Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:105)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823693Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823820Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.823938Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824265Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824405Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824570Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824708Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824829Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.824950Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.826439Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.826601Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.827315Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.827539Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.849873Z","level":"info","event":"25/12/18 10:57:06 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:06.853542Z","level":"info","event":"25/12/18 10:57:06 INFO SharedState: Warehouse path is 'file:/opt/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:09.645990Z","level":"info","event":"25/12/18 10:57:09 INFO CatalogUtil: Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.566196Z","level":"info","event":"25/12/18 10:57:12 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.566448Z","level":"info","event":"25/12/18 10:57:12 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.582636Z","level":"info","event":"25/12/18 10:57:12 INFO SparkUI: Stopped Spark web UI at http://39a6647a13a1:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.602876Z","level":"info","event":"25/12/18 10:57:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.617813Z","level":"info","event":"25/12/18 10:57:12 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.618321Z","level":"info","event":"25/12/18 10:57:12 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.628699Z","level":"info","event":"25/12/18 10:57:12 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.634062Z","level":"info","event":"25/12/18 10:57:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.645148Z","level":"info","event":"25/12/18 10:57:12 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.645370Z","level":"info","event":"25/12/18 10:57:12 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.646483Z","level":"info","event":"25/12/18 10:57:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-0dc83bd2-1d77-4905-b1fe-98dd38c0c34f","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.652314Z","level":"info","event":"25/12/18 10:57:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-e7e54dfe-913f-47ff-85ef-f1875329e5af","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:12.657370Z","level":"info","event":"25/12/18 10:57:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-e7e54dfe-913f-47ff-85ef-f1875329e5af/pyspark-0e4b765d-70ff-4194-b180-63008f8d78c2","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:13.041629Z","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":110}
{"timestamp":"2025-12-18T10:57:13.042990Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b311b-1214-73d8-8c53-4173085de522'), task_id='create_namespace', dag_id='youtube_iceberg_pipeline', run_id='manual__2025-12-18T10:56:56.314021+00:00', try_number=1, dag_version_id=UUID('019b310c-6ed5-77d7-b13f-281f142c1798'), map_index=-1, hostname='d7cb02c224fd', context_carrier={}, task=<Task(BashOperator): create_namespace>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 12, 18, 10, 56, 57, 803067, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1352}
