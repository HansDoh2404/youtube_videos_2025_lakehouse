{"timestamp":"2025-12-18T10:57:13.518226Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-18T10:57:13.519353Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/lakehouse.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-18T10:57:13.558809Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2025-12-18T10:57:13.559881Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '\\n        docker exec spark-iceberg         spark-submit /home/iceberg/jobs/create_table.py\\n        ']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":88}
{"timestamp":"2025-12-18T10:57:13.572872Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2025-12-18T10:57:16.960381Z","level":"info","event":"25/12/18 10:57:16 INFO SparkContext: Running Spark version 3.5.5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:16.963944Z","level":"info","event":"25/12/18 10:57:16 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:16.964434Z","level":"info","event":"25/12/18 10:57:16 INFO SparkContext: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.049276Z","level":"info","event":"25/12/18 10:57:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.209665Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.210197Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.211072Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.214052Z","level":"info","event":"25/12/18 10:57:17 INFO SparkContext: Submitted application: create_table.py","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.237227Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.247522Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.248475Z","level":"info","event":"25/12/18 10:57:17 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.314267Z","level":"info","event":"25/12/18 10:57:17 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.314805Z","level":"info","event":"25/12/18 10:57:17 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.317168Z","level":"info","event":"25/12/18 10:57:17 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.317398Z","level":"info","event":"25/12/18 10:57:17 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.318579Z","level":"info","event":"25/12/18 10:57:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.707366Z","level":"info","event":"25/12/18 10:57:17 INFO Utils: Successfully started service 'sparkDriver' on port 44919.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.745006Z","level":"info","event":"25/12/18 10:57:17 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.795651Z","level":"info","event":"25/12/18 10:57:17 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.829067Z","level":"info","event":"25/12/18 10:57:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.829316Z","level":"info","event":"25/12/18 10:57:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.833654Z","level":"info","event":"25/12/18 10:57:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.861106Z","level":"info","event":"25/12/18 10:57:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-55afd57a-2dd6-4a2d-8383-2c87c8558bff","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.884823Z","level":"info","event":"25/12/18 10:57:17 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:17.914522Z","level":"info","event":"25/12/18 10:57:17 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.091787Z","level":"info","event":"25/12/18 10:57:18 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.194886Z","level":"info","event":"25/12/18 10:57:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.207866Z","level":"info","event":"25/12/18 10:57:18 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.499171Z","level":"info","event":"25/12/18 10:57:18 INFO Executor: Starting executor ID driver on host 39a6647a13a1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.499419Z","level":"info","event":"25/12/18 10:57:18 INFO Executor: OS info Linux, 6.10.14-linuxkit, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.499580Z","level":"info","event":"25/12/18 10:57:18 INFO Executor: Java version 17.0.14","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.520332Z","level":"info","event":"25/12/18 10:57:18 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.520590Z","level":"info","event":"25/12/18 10:57:18 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@594de03b for default.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.584112Z","level":"info","event":"25/12/18 10:57:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35627.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.584356Z","level":"info","event":"25/12/18 10:57:18 INFO NettyBlockTransferService: Server created on 39a6647a13a1:35627","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.587367Z","level":"info","event":"25/12/18 10:57:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.605728Z","level":"info","event":"25/12/18 10:57:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 39a6647a13a1, 35627, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.613887Z","level":"info","event":"25/12/18 10:57:18 INFO BlockManagerMasterEndpoint: Registering block manager 39a6647a13a1:35627 with 434.4 MiB RAM, BlockManagerId(driver, 39a6647a13a1, 35627, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.619522Z","level":"info","event":"25/12/18 10:57:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 39a6647a13a1, 35627, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.621648Z","level":"info","event":"25/12/18 10:57:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 39a6647a13a1, 35627, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:18.984411Z","level":"info","event":"25/12/18 10:57:18 INFO SingleEventLogFileWriter: Logging events to file:/home/iceberg/spark-events/local-1766055438370.inprogress","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569133Z","level":"info","event":"25/12/18 10:57:19 WARN SparkSession: Cannot use org.projectnessie.spark.extensions.NessieSparkSessionExtensions to configure session extensions.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569397Z","level":"info","event":"java.lang.ClassNotFoundException: org.projectnessie.spark.extensions.NessieSparkSessionExtensions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569568Z","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569695Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569821Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.569916Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570039Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570128Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570231Z","level":"info","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570345Z","level":"info","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570440Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1367)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570542Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570618Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570690Z","level":"info","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570759Z","level":"info","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570849Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$applyExtensions(SparkSession.scala:1365)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.570933Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:105)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571051Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571136Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571220Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571302Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571383Z","level":"info","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571465Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571567Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571648Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571730Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571812Z","level":"info","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.571893Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.572005Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:19.572095Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:21.142766Z","level":"info","event":"25/12/18 10:57:21 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:21.146244Z","level":"info","event":"25/12/18 10:57:21 INFO SharedState: Warehouse path is 'file:/opt/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.941245Z","level":"info","event":"25/12/18 10:57:22 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.941782Z","level":"info","event":"25/12/18 10:57:22 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.953238Z","level":"info","event":"25/12/18 10:57:22 INFO SparkUI: Stopped Spark web UI at http://39a6647a13a1:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.971433Z","level":"info","event":"25/12/18 10:57:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.988049Z","level":"info","event":"25/12/18 10:57:22 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.988741Z","level":"info","event":"25/12/18 10:57:22 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:22.999504Z","level":"info","event":"25/12/18 10:57:22 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.005802Z","level":"info","event":"25/12/18 10:57:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.028534Z","level":"info","event":"25/12/18 10:57:23 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.028750Z","level":"info","event":"25/12/18 10:57:23 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.030274Z","level":"info","event":"25/12/18 10:57:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-44fe8b53-b38a-4e4b-bbe2-5437c3cfa297","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.035572Z","level":"info","event":"25/12/18 10:57:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-44fe8b53-b38a-4e4b-bbe2-5437c3cfa297/pyspark-1295a694-f489-411c-a773-cfa3d21ad2e1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.041190Z","level":"info","event":"25/12/18 10:57:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-382169ef-634a-46e0-b98a-79ef7c3b3823","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":106}
{"timestamp":"2025-12-18T10:57:23.090313Z","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":110}
{"timestamp":"2025-12-18T10:57:23.091802Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b311b-1215-73e5-ac62-a8aaddb38a64'), task_id='create_table', dag_id='youtube_iceberg_pipeline', run_id='manual__2025-12-18T10:56:56.314021+00:00', try_number=1, dag_version_id=UUID('019b310c-6ed5-77d7-b13f-281f142c1798'), map_index=-1, hostname='d7cb02c224fd', context_carrier={}, task=<Task(BashOperator): create_table>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 12, 18, 10, 57, 13, 259310, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1352}
